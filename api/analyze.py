# api/analyze.py

from fastapi import FastAPI, File, UploadFile, HTTPException, Form
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
import librosa
import numpy as np
import io
from pydub import AudioSegment
import random
import traceback
import hashlib

API_VERSION = "1.3.0"

app = FastAPI()

# CORS (í•„ìš” ì‹œ ë„ë©”ì¸ ì¶”ê°€)
# origins = ["http://localhost:5173", "http://127.0.0.1:5173"]
origins = ["*"] # ğŸš¨ ì´ë ‡ê²Œ ëª¨ë“  ì£¼ì†Œë¥¼ í—ˆìš©í•˜ë„ë¡ ë³€ê²½í•©ë‹ˆë‹¤. (í…ŒìŠ¤íŠ¸ìš©)

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- ì œí•œ/ê°€ë“œ ìƒìˆ˜ ---
MIN_SEC = 0.5
MAX_SEC = 12
MAX_BYTES = 10 * 1024 * 1024  # 10MB

# --- ë°ì´í„° í’€ ---
voice_analysis_data = {
    "age_groups": {
        "10s": {"range": "10ëŒ€", "humor": ["ëª©ì†Œë¦¬ì—ì„œ 'ì—„ë§ˆ ìš©ëˆ ì˜¬ë ¤ë‹¬ë¼'ëŠ” ê°„ì ˆí•¨ì´ ëŠê»´ì ¸ìš”! ğŸŒ¸", "ë¼ë©´ ë“ì´ëŠ” ì†Œë¦¬ë§Œ ë“¤ì–´ë„ ë‹¬ë ¤ì˜¬ ê²ƒ ê°™ì€ ëª©ì†Œë¦¬! âš¡", "ë°¤ 12ì‹œì— 'ìˆ™ì œ ì–¸ì œ í•˜ì§€?' í•˜ëŠ” ëª©ì†Œë¦¬ë„¤ìš”! ğŸ“±", "ì²­ì¶˜ ë“œë¼ë§ˆì—ì„œ 'ì•¼, ë„ˆ ì¢‹ì•„í•´' ê³ ë°±í•  ëª©ì†Œë¦¬! ğŸ­", "ìƒˆë¡œ ë‚˜ì˜¨ ì¤„ì„ë§ì„ ì¼ì£¼ì¼ ë§Œì— ë§ˆìŠ¤í„°í•  ê²ƒ ê°™ì•„ìš”!", "ì—ë„ˆì§€ ë“œë§í¬ê°€ ëª©ì†Œë¦¬ë¡œ ë³€í•œ ëŠë‚Œ!"]},
        "20s_early": {"range": "20ëŒ€ ì´ˆë°˜", "humor": ["ëŒ€í•™ ê³¼ì œ ë§ˆê° 2ì‹œê°„ ì „ì˜ ì ˆë§ê³¼ í¬ë§ì´ ê³µì¡´í•˜ëŠ” ëª©ì†Œë¦¬! ğŸ“", "ë°¤ìƒˆ íŒ€í”Œí•˜ê³  'ì´ë²ˆì—” ì§„ì§œ A+ ë°›ì„ ê±°ì•¼' í•˜ëŠ” ëª©ì†Œë¦¬!", "MTì—ì„œ 'ìš°ë¦¬ ê³¼ ìµœê³ !' ì™¸ì¹  ëª©ì†Œë¦¬ì—ìš”!", "'ì˜¤ëŠ˜ ë­ ë¨¹ì§€?'ê°€ ì¸ìƒ ìµœëŒ€ ê³ ë¯¼ì¸ ëª©ì†Œë¦¬!", "ê°œê°•íŒŒí‹° ì£¼ìµœì ëª©ì†Œë¦¬ë„¤ìš”!", "ì¹œêµ¬ ë²ˆí˜¸ ë¬¼ì–´ë´ë‹¬ë¼ê³  ë¶€íƒë°›ì„ ëª©ì†Œë¦¬!"]},
        "20s_late": {"range": "20ëŒ€ í›„ë°˜", "humor": ["ì´ì œ ë§‰ 'ì–´ë¥¸'ì´ë¼ëŠ” ê°€ë©´ì„ ì“°ê¸° ì‹œì‘í•œ ëª©ì†Œë¦¬! ğŸº", "í‡´ê·¼ê¸¸ì— 'ì˜¤ëŠ˜ë„ ê³ ìƒí–ˆë‹¤' í˜¼ì£ë§í•  ëª©ì†Œë¦¬ë„¤ìš”!", "ì²« ì›”ê¸‰ìœ¼ë¡œ 'ì´ì œì•¼ ì‚¬ëŒ ëë‹¤' ëŠë¼ëŠ” ëª©ì†Œë¦¬!", "ì£¼ë§ ì•½ì† ì—†ìœ¼ë©´ ì¸ì‹¸ ìê²© ë°•íƒˆë‹¹í•  ê²ƒ ê°™ì€ ëª©ì†Œë¦¬!", "ì—°ì• í•  ë•Œ ê°€ì¥ ì„¤ë ˆì§€ë§Œ í˜„ì‹¤ì€ ì†”ë¡œì¸ ëª©ì†Œë¦¬ ğŸ’•", "ë…ë¦½ í›„ 'ì§‘ì—ì„œ ì†ì˜·ë§Œ ì…ê³  ë‹¤ë‹ˆëŠ” ììœ 'ë¥¼ ë§Œë½í•˜ëŠ” ëª©ì†Œë¦¬!"]},
        "30s_early": {"range": "30ëŒ€ ì´ˆë°˜", "humor": ["ì•ˆì •ê°ì€ ìˆëŠ”ë° ì—¬ì „íˆ ê²Œì„ ë°¤ìƒˆëŠ” ëª©ì†Œë¦¬ì˜ˆìš”.", "ë„·í”Œë¦­ìŠ¤ ì •ì£¼í–‰ì´ ìµœê³ ì˜ íë§ì´ë¼ê³  í™•ì‹ í•˜ëŠ” ëª©ì†Œë¦¬!", "'ì•„, í—ˆë¦¬ì•¼...' ì²« ì‹ ìŒì†Œë¦¬ë¥¼ ë‚¸ ëª©ì†Œë¦¬!", "íšŒì‚¬ì—ì„œ 'ë¯¿ê³  ë§¡ê¸¸ ìˆ˜ ìˆëŠ”' ëª©ì†Œë¦¬ ğŸ’¼", "ê²°í˜¼ì‹ ì¶•ì‚¬ì—ì„œ ì›ƒìŒê³¼ ê°ë™ì„ ë™ì‹œì— ì¤„ ëª©ì†Œë¦¬!", "ì»¤í”¼ ì—†ìœ¼ë©´ ì¢€ë¹„ê°€ ë˜ëŠ” ëª©ì†Œë¦¬ â˜•"]},
        "30s_late": {"range": "30ëŒ€ í›„ë°˜", "humor": ["ê¹Šì´ëŠ” ìˆëŠ”ë° ì•„ì§ ìœ íŠœë¸Œ ì•Œê³ ë¦¬ì¦˜ì— ë‹¹í•˜ëŠ” ëª©ì†Œë¦¬! ğŸ’°", "ì¬í…Œí¬ ìœ íŠœë¸Œ ë³´ë©´ì„œ 'ë‚˜ë„ ë¶€ì ë  ìˆ˜ ìˆì–´' í•˜ëŠ” ëª©ì†Œë¦¬!", "ìœ¡ì•„ í˜„ì‹¤ì— ì¹˜ì—¬ë„ ì•„ì´ ì•ì—ì„  ì²œì‚¬ê°€ ë˜ëŠ” ëª©ì†Œë¦¬ ğŸ‘¶", "ìº í•‘ ê°€ì„œ 'ìì—°ì´ ìµœê³ ì•¼' í•˜ì§€ë§Œ ì™€ì´íŒŒì´ ì°¾ëŠ” ëª©ì†Œë¦¬!", "ì¸ìƒ í™©ê¸ˆê¸°ë¼ì§€ë§Œ ì²´ë ¥ì€ ì´ë¯¸ í•˜í–¥ê³¡ì„ ì¸ ëª©ì†Œë¦¬! âœ¨", "'ì§‘ì´ ì²œêµ­'ì´ë¼ëŠ” ì§„ë¦¬ë¥¼ ê¹¨ë‹¬ì€ ëª©ì†Œë¦¬!"]},
        "40s_early": {"range": "40ëŒ€ ì´ˆë°˜", "humor": ["í¸ì•ˆí•˜ì§€ë§Œ ê°‘ìê¸° 'ìš”ì¦˜ ì• ë“¤ì€...' í•˜ê³  ì‹¶ì–´ì§€ëŠ” ëª©ì†Œë¦¬!", "ì™€ì¸ ë§ˆì‹œë©´ì„œ 'ì¸ìƒì„ ë…¼í•˜ê³ ' ì‹¶ì–´ì§€ëŠ” ëª©ì†Œë¦¬ ğŸ·", "í›„ë°°ë“¤ì—ê²Œ ë°¥ ì‚¬ì£¼ë©´ì„œ 'ë‚´ ì Šì—ˆì„ ë•ŒëŠ”' ì‹œì „í•  ëª©ì†Œë¦¬!", "ì•„ì´ ìˆ™ì œ ë„ì™€ì£¼ë‹¤ê°€ 'ì´ê²Œ ë­ì•¼?' í•  ëª©ì†Œë¦¬ ğŸ“", "ê²½í—˜ë‹´ì´ ë ˆì „ë“œê°€ ëœ ëª©ì†Œë¦¬ ğŸ“š", "ê³¨í”„ ì¹˜ë©´ì„œ 'ìŠ¤íŠ¸ë ˆìŠ¤ í‘¸ëŠ”' ëª©ì†Œë¦¬!"]},
        "40s_late": {"range": "40ëŒ€ í›„ë°˜", "humor": ["ì§€í˜œë¡­ì§€ë§Œ ì•„ì§ ìŠ¤ë§ˆíŠ¸í° ê¸°ëŠ¥ì„ ë‹¤ ëª¨ë¥´ëŠ” ëª©ì†Œë¦¬!", "'ë‚´ê°€ ë„ˆ ë•ŒëŠ”...' ì „ì„¤ì˜ ì‹œì‘ì„ ì•Œë¦¬ëŠ” ëª©ì†Œë¦¬!", "ì¸ìƒì˜ ë‹¨ë§›ì„ ì•„ëŠ” ë™ì‹œì— ì“´ë§›ë„ ì•„ëŠ” ëª©ì†Œë¦¬!", "ë‹¤í ë³´ë©´ì„œ 'ì—­ì‹œ ì˜›ë‚ ì´ ì¢‹ì•˜ì–´' í•  ëª©ì†Œë¦¬!", "ê°€ì¡±ì—¬í–‰ ê³„íš ì„¸ìš°ëŠ” ê²Œ ì·¨ë¯¸ê°€ ëœ ëª©ì†Œë¦¬!", "ì¹œêµ¬ ëª¨ì„ì—ì„œ 'ê±´ê°•ì´ ìµœê³ ì•¼' ì™¸ì¹˜ëŠ” ëª©ì†Œë¦¬!"]},
        "50s_plus": {"range": "50ëŒ€ ì´ìƒ", "humor": ["ëª¨ë“  ê²ƒì„ ë‹¤ ê²ªì–´ë³¸ 'ì¸ìƒ ê³ ìˆ˜'ì˜ ì—¬ìœ ë¡œìš´ ëª©ì†Œë¦¬!", "ì°¨ í•œ ì”ì— 'ì¸ìƒ ì² í•™'ì„ ë‹´ì•„ë‚¼ ìˆ˜ ìˆëŠ” ëª©ì†Œë¦¬ ğŸµ", "'ì´ì œì•¼ ì§„ì§œ ë‚´ ì¸ìƒì´ ì‹œì‘ì´ì•¼' í•˜ëŠ” ëª©ì†Œë¦¬ ğŸ­", "ì†ì ì†ë…€ì—ê²Œ 'ì˜›ë‚ ì— í• ì•„ë²„ì§€ëŠ”...' ì‹œì „í•˜ëŠ” ëª©ì†Œë¦¬!", "ë“±ì‚°ë³µì´ ì¼ìƒë³µì´ ëœ ëª©ì†Œë¦¬ ğŸ”ï¸", "í…ƒë°­ì—ì„œ 'ë‚´ê°€ ê¸°ë¥¸ ë°°ì¶”ê°€ ìµœê³ ì•¼' í•˜ëŠ” ëª©ì†Œë¦¬!"]},
    },
    "animalTypes": [
        {"id": "cat", "type": "ê³ ì–‘ì´ìƒ", "emoji": "ğŸ±", "desc": "ì¸¤ë°ë ˆì˜ ì™„ì„±ì²´, ê´€ì‹¬ì—†ëŠ” ì²™ í•˜ì§€ë§Œ ì‚¬ì‹¤ ê´€ì¢…"},
        {"id": "dog", "type": "ê°•ì•„ì§€ìƒ", "emoji": "ğŸ¶", "desc": "ì„¸ìƒ ëª¨ë“  ì‚¬ëŒì´ ì¢‹ì€ ì‚¬ëŒì¼ ê±°ë¼ê³  ë¯¿ëŠ” ìˆœìˆ˜í•¨"},
        {"id": "bear", "type": "ê³°ìƒ", "emoji": "ğŸ»", "desc": "í¬ê·¼í•œ ì¸ê°„ ë‹´ìš”, ì•ˆê¸°ê³  ì‹¶ê²Œ ë§Œë“œëŠ” ë§ˆì„±ì˜ ì²´ì§ˆ"},
        {"id": "fox", "type": "ì—¬ìš°ìƒ", "emoji": "ğŸ¦Š", "desc": "ê³„ì‚°ê¸°ë³´ë‹¤ ë¹ ë¥¸ ë‘ë‡Œ, ëˆˆë¹›ë§Œìœ¼ë¡œ ì‚¬ëŒ í™€ë¦¬ëŠ” ë§ˆë²•ì‚¬"},
        {"id": "hamster", "type": "í–„ìŠ¤í„°ìƒ", "emoji": "ğŸ¹", "desc": "ì…ì— ìŒì‹ ê°€ë“ ë„£ê³ ë„ ê·€ì—¬ìš´ ë°˜ì¹™ê¸‰ ì™¸ëª¨"},
        {"id": "lion", "type": "ì‚¬ììƒ", "emoji": "ğŸ¦", "desc": "ê°€ë§Œíˆ ìˆì–´ë„ í¬ìŠ¤ í­ë°œ, ì²œìƒì²œí•˜ ìœ ì•„ë…ì¡´"},
        {"id": "rabbit", "type": "í† ë¼ìƒ", "emoji": "ğŸ°", "desc": "ê¹œì°í•¨ìœ¼ë¡œ ì„¸ìƒì„ ì •ë³µí•˜ëŠ” ì¤‘, ë³´í˜¸ë³¸ëŠ¥ ìê·¹ ì „ë¬¸ê°€"},
        {"id": "wolf", "type": "ëŠ‘ëŒ€ìƒ", "emoji": "ğŸº", "desc": "ì•¼ì„±ë¯¸ ì² ì²  í˜ëŸ¬ë„˜ì¹˜ëŠ” ë§¤ë ¥, ê¸¸ë“¤ì—¬ì§€ì§€ ì•ŠëŠ” ììœ ë¡œìš´ ì˜í˜¼"}
    ],
    "personalityTypes": [
        {"id": "leader", "type": "íƒ€ê³ ë‚œ ë¦¬ë”í˜•", "emoji": "ğŸ‘‘", "color": "#f59e0b"},
        {"id": "emotional", "type": "ë”°ëœ»í•œ ê°ì„±í˜•", "emoji": "ğŸ’", "color": "#ec4899"},
        {"id": "maker", "type": "ë¶„ìœ„ê¸° ë©”ì´ì»¤í˜•", "emoji": "ğŸ‰", "color": "#8b5cf6"},
        {"id": "stable", "type": "ê¹Šê³  ì°¨ë¶„í•œ ì•ˆì •í˜•", "emoji": "ğŸ§˜", "color": "#06b6d4"},
        {"id": "humorous", "type": "ìœ ë¨¸ëŸ¬ìŠ¤í•œ ì¬ë¯¸í˜•", "emoji": "ğŸ˜„", "color": "#10b981"},
        {"id": "artist", "type": "ì°½ì˜ì ì¸ ì•„í‹°ìŠ¤íŠ¸í˜•", "emoji": "ğŸ¨", "color": "#f97316"},
        {"id": "analytical", "type": "ì§€ì ì´ê³  ë¶„ì„ì ì¸ í˜•", "emoji": "ğŸ¤“", "color": "#6366f1"},
        {"id": "active", "type": "í™œë™ì ì¸ ìŠ¤í¬ì¸ í˜•", "emoji": "ğŸƒ", "color": "#ef4444"},
    ],
    "compatibilityJobs": ["ë¼ë””ì˜¤ DJ", "ì„±ìš°", "ê°€ìˆ˜", "ì•„ë‚˜ìš´ì„œ", "íŒŸìºìŠ¤í„°", "ìœ íŠœë²„", "êµì‚¬", "ìƒë‹´ì‚¬", "ë°°ìš°", "MC", "ì˜¤ë””ì˜¤ë¶ ë‚´ë ˆì´í„°", "í†µì—­ì‚¬", "ì½œì„¼í„° ìƒë‹´ì›", "ê°•ì‚¬"],
    "specialTags": ["ASMR ì²œì¬", "ëª©ì†Œë¦¬ ë§ˆì•½", "ê·€í˜¸ê°• ì£¼ì¸ê³µ", "ë³´ì´ìŠ¤ í”¼ì…”", "ìŒì„± ì¹˜ë£Œì‚¬", "íë§ ë³´ì´ìŠ¤", "ë§¤ë ¥ ë°œì‚°ê¸°", "ì¹´ë¦¬ìŠ¤ë§ˆ í­ë°œ", "ëª©ì†Œë¦¬ ê¿€", "ë³´ì»¬ DNA", "ìŒì„± ë§ˆìˆ ì‚¬", "ê·€ê° ì œì¡°ê¸°"],
    "voiceColors": ["ë£¨ë¹„ ë ˆë“œ", "ì‚¬íŒŒì´ì–´ ë¸”ë£¨", "ì—ë©”ë„ë“œ ê·¸ë¦°", "ê³¨ë“  ì˜ë¡œìš°", "ì•„ë©”ì‹œìŠ¤íŠ¸ í¼í”Œ", "ë‹¤ì´ì•„ëª¬ë“œ í™”ì´íŠ¸", "ì˜¤ë‹‰ìŠ¤ ë¸”ë™", "ë¡œì¦ˆ ê³¨ë“œ", "ì‹¤ë²„ í™”ì´íŠ¸", "ì½”ë°œíŠ¸ ë¸”ë£¨"]
}

# --- ìœ í‹¸ & ì „ì²˜ë¦¬ ---

def trim_and_normalize(y, sr):
    y = librosa.util.normalize(y)
    y, _ = librosa.effects.trim(y, top_db=30)
    return y

def median_filter_1d(x, k=5):
    if len(x) < k:
        return x
    pad = k // 2
    xp = np.pad(x, (pad, pad), mode='edge')
    return np.array([np.median(xp[i:i + k]) for i in range(len(x))])

# --- í”¼ì¹˜ í†µí•© ì¶”ì¶œ (median Hz, std Hz, std cents) ---

def extract_pitch_stats(y, sr):
    f0, _, _ = librosa.pyin(
        y,
        fmin=librosa.note_to_hz('C2'),
        fmax=librosa.note_to_hz('C7'),
        frame_length=1024,
        hop_length=256,
        center=True
    )
    v = f0[~np.isnan(f0)]
    if len(v) == 0:
        return 150.0, 15.0, 80.0  # ì•ˆì „ ê¸°ë³¸ê°’
    v = median_filter_1d(v, k=5)
    med = float(np.median(v))
    if len(v) == 1:
        return med, 15.0, 80.0
    std_hz = float(np.std(v))
    std_cents = float(1200.0 * np.std(np.log2(v / med)))  # í”¼ì¹˜ ë¶ˆë³€ì„±
    return med, std_hz, std_cents

# --- ì—ë„ˆì§€ (ë ˆë²¨ ë¬´ê°í™”) ---

def analyze_energy(y):
    rms = librosa.feature.rms(y=y)[0]
    if np.all(rms == 0):
        return 0.0
    db = librosa.amplitude_to_db(rms, ref=np.max)  # 0..-inf
    # í‰ê·  dBë¥¼ 0..1ë¡œ ë§¤í•‘(ì•½ -60~0dB ê°€ì •)
    norm = np.clip((db.mean() + 60.0) / 60.0, 0.0, 1.0)
    return float(norm)

# --- ë§í•˜ê¸° ì†ë„ í”„ë¡ì‹œ (ZCR + Spectral Flux í•˜ì´ë¸Œë¦¬ë“œ) ---

def analyze_speaking_rate(y, sr):
    intervals = librosa.effects.split(y, top_db=30)
    yv = np.concatenate([y[s:e] for s, e in intervals]) if len(intervals) else y
    z = float(np.mean(librosa.feature.zero_crossing_rate(y=yv, frame_length=1024, hop_length=256)))
    S = np.abs(librosa.stft(yv, n_fft=1024, hop_length=256))
    flux = float(np.mean(np.maximum(0, np.diff(S, axis=1)).mean(axis=0)))
    proxy = 0.85 * z + 0.15 * (flux / np.maximum(S.mean(), 1e-6))  # ê°€ë²¼ìš´ ë³´ì •
    # ê²½í—˜ì  ë²”ìœ„: 0.03..0.18 â†’ 70..180
    return float(70 + (np.clip(proxy, 0.03, 0.18) - 0.03) / (0.18 - 0.03) * (180 - 70))

# --- ì¡°í™”ë„(HNR) ì•ˆì „í™” ---

def analyze_harmonicity(y):
    y_h, y_p = librosa.effects.hpss(y)
    he = float(np.sum(y_h**2) + 1e-12)
    pe = float(np.sum(y_p**2) + 1e-12)
    hnr = 10.0 * np.log10(he / pe)
    return float(np.clip(hnr, -20.0, 20.0))

# --- ìŠ¤í™íŠ¸ëŸ¼ ì„¼íŠ¸ë¡œì´ë“œ ---

def analyze_spectral_centroid(y, sr):
    return float(np.mean(librosa.feature.spectral_centroid(y=y, sr=sr)))

# --- ë‚˜ì´ëŒ€ ì¶”ì • ê·œì¹™ ---

def get_age_key_female(pitch, spectral_centroid, energy_norm01):
    """ì—¬ì„± ëª©ì†Œë¦¬ ë‚˜ì´ëŒ€ ì¶”ì • (ì—ë„ˆì§€: 0~1 ì •ê·œí™” ê¸°ì¤€)"""
    if pitch > 245: return "10s"
    elif pitch > 220: return "20s_early"
    elif pitch > 200: return "20s_late"
    elif pitch > 185: return "30s_early" if energy_norm01 > 0.5 else "30s_late"
    elif pitch > 170: return "40s_early" if spectral_centroid > 2200 else "40s_late"
    else: return "50s_plus"

def get_age_key_male(pitch, spectral_centroid, energy_norm01):
    """ë‚¨ì„± ëª©ì†Œë¦¬ ë‚˜ì´ëŒ€ ì¶”ì • (ì—ë„ˆì§€: 0~1 ì •ê·œí™” ê¸°ì¤€)"""
    if pitch > 165: return "10s"
    elif pitch > 140: return "20s_early"
    elif pitch > 125: return "20s_late"
    elif pitch > 110: return "30s_early" if energy_norm01 > 0.5 else "30s_late"
    elif pitch > 95: return "40s_early" if spectral_centroid > 1800 else "40s_late"
    else: return "50s_plus"

# --- í”„ë¡œí•„ ì‚°ì¶œ (ì¹˜ìš°ì¹¨ ì™„í™” ì„ê³„ê°’ ìƒí–¥) ---

def get_voice_profile(features):
    profile = set()
    # pitch band
    if features['pitch'] > 180: profile.add('high_pitch')
    elif features['pitch'] < 130: profile.add('low_pitch')
    else: profile.add('mid_pitch')
    # energy (0~1)  â† high>0.75, low<0.30
    if features['energy'] > 0.75: profile.add('high_energy')
    elif features['energy'] < 0.30: profile.add('low_energy')
    else: profile.add('mid_energy')
    # clarity
    if features['harmonicity'] > 7.0: profile.add('clear_voice')
    elif features['harmonicity'] < 3.0: profile.add('husky_voice')
    else: profile.add('soft_voice')
    # stability: pitch std in cents â† dynamic>110c
    pitch_var = features.get('pitch_std_cents', None)
    if pitch_var is not None:
        profile.add('dynamic_tone' if pitch_var > 110.0 else 'stable_tone')
    else:
        profile.add('dynamic_tone' if features['pitch_std'] > 35 else 'stable_tone')
    return profile

# --- ì§ì—… ê°€ì¤‘ì¹˜ ìŠ¤ì½”ì–´ëŸ¬ (ì ë¦¼ ë°©ì§€) ---

def select_job_with_scores(profile, features, audio_bytes=None):
    jobs = [
        "ì•„ë‚˜ìš´ì„œ","MC","ì˜¤ë””ì˜¤ë¶ ë‚´ë ˆì´í„°","ë°°ìš°","ìœ íŠœë²„","ìƒë‹´ì‚¬",
        "ì„±ìš°","ê°€ìˆ˜","êµì‚¬","íŒŸìºìŠ¤í„°","ê°•ì‚¬","í†µì—­ì‚¬","ë¼ë””ì˜¤ DJ"
    ]
    scores = {j: 0.0 for j in jobs}

    tempo = float(features.get("tempo", 110.0))
    fast = tempo >= 120
    slow = tempo <= 95
    mid_speed = 95 < tempo < 130

    def add(job, w): scores[job] += w

    # ì•„ë‚˜ìš´ì„œ
    if 'clear_voice' in profile: add("ì•„ë‚˜ìš´ì„œ", 2.5)
    if 'stable_tone' in profile: add("ì•„ë‚˜ìš´ì„œ", 2.0)
    if 'mid_energy' in profile:  add("ì•„ë‚˜ìš´ì„œ", 1.0)
    if mid_speed:                add("ì•„ë‚˜ìš´ì„œ", 1.0)

    # MC (ì—„ê²©: ë¹ ë¥¸ ì†ë„ + ì—ë„ˆì§€ + ë‹¤ì´ë‚´ë¯¹)
    if 'high_energy' in profile and 'dynamic_tone' in profile: add("MC", 2.0)
    if fast:                                              add("MC", 2.0)
    if 'clear_voice' in profile:                          add("MC", 1.0)

    # ì˜¤ë””ì˜¤ë¶ ë‚´ë ˆì´í„°
    if 'low_energy' in profile: add("ì˜¤ë””ì˜¤ë¶ ë‚´ë ˆì´í„°", 2.0)
    if 'soft_voice' in profile: add("ì˜¤ë””ì˜¤ë¶ ë‚´ë ˆì´í„°", 2.0)
    if 'stable_tone' in profile: add("ì˜¤ë””ì˜¤ë¶ ë‚´ë ˆì´í„°", 1.0)
    if slow:                     add("ì˜¤ë””ì˜¤ë¶ ë‚´ë ˆì´í„°", 1.5)

    # ë°°ìš°
    if 'dynamic_tone' in profile: add("ë°°ìš°", 2.0)
    if 'husky_voice' in profile:  add("ë°°ìš°", 1.0)
    if 'high_energy' in profile:  add("ë°°ìš°", 0.5)

    # ìœ íŠœë²„
    if 'high_energy' in profile: add("ìœ íŠœë²„", 1.5)
    if 'clear_voice' in profile: add("ìœ íŠœë²„", 1.0)
    if 'dynamic_tone' in profile: add("ìœ íŠœë²„", 1.0)

    # ìƒë‹´ì‚¬
    if 'soft_voice' in profile:  add("ìƒë‹´ì‚¬", 2.0)
    if 'stable_tone' in profile: add("ìƒë‹´ì‚¬", 1.0)
    if 'low_energy' in profile:  add("ìƒë‹´ì‚¬", 1.0)

    # ì„±ìš°
    if 'clear_voice' in profile: add("ì„±ìš°", 2.0)
    if 'dynamic_tone' in profile: add("ì„±ìš°", 1.0)
    if 'mid_energy' in profile:  add("ì„±ìš°", 1.0)

    # ê°€ìˆ˜
    if 'clear_voice' in profile: add("ê°€ìˆ˜", 1.0)
    if 'high_pitch' in profile:  add("ê°€ìˆ˜", 1.0)
    if 'dynamic_tone' in profile: add("ê°€ìˆ˜", 0.5)

    # êµì‚¬
    if 'stable_tone' in profile: add("êµì‚¬", 2.0)
    if 'mid_energy' in profile:  add("êµì‚¬", 1.0)

    # íŒŸìºìŠ¤í„°
    if 'dynamic_tone' in profile: add("íŒŸìºìŠ¤í„°", 1.0)
    if 'soft_voice' in profile:   add("íŒŸìºìŠ¤í„°", 1.0)
    if 'mid_energy' in profile:   add("íŒŸìºìŠ¤í„°", 0.5)

    # ê°•ì‚¬
    if 'high_energy' in profile: add("ê°•ì‚¬", 2.0)
    if fast:                     add("ê°•ì‚¬", 1.0)
    if 'clear_voice' in profile: add("ê°•ì‚¬", 0.5)

    # í†µì—­ì‚¬
    if 'clear_voice' in profile: add("í†µì—­ì‚¬", 1.0)
    if 'stable_tone' in profile: add("í†µì—­ì‚¬", 1.0)
    if mid_speed:                add("í†µì—­ì‚¬", 1.0)
    if 'low_energy' in profile:  add("í†µì—­ì‚¬", 0.5)

    # ë¼ë””ì˜¤ DJ
    if 'soft_voice' in profile:  add("ë¼ë””ì˜¤ DJ", 1.0)
    if 'low_energy' in profile:  add("ë¼ë””ì˜¤ DJ", 0.5)
    if 'stable_tone' in profile: add("ë¼ë””ì˜¤ DJ", 0.5)

    ranked = sorted(scores.items(), key=lambda kv: kv[1], reverse=True)
    top3 = ranked[:3]
    if audio_bytes is not None and len(top3) > 1 and top3[0][1] == top3[1][1]:
        h = int(hashlib.md5(audio_bytes).hexdigest(), 16)
        top3 = sorted(top3, key=lambda kv: (kv[1], (h ^ hash(kv[0])) & 0xffff), reverse=True)

    best_job = top3[0][0]
    candidates = [{"job": j, "score": round(s, 2)} for j, s in top3]
    return best_job, candidates

# --- ì„¸ë¶€ ê²°ê³¼ ë§¤í•‘ (ì§ì—…=ê°€ì¤‘ì¹˜ ìŠ¤ì½”ì–´ëŸ¬ ì‚¬ìš©) ---

def analyze_details_based_on_profile(profile, features=None, audio_bytes=None):
    """ìŒì„± í”„ë¡œí•„ì„ ê¸°ë°˜ìœ¼ë¡œ ëª¨ë“  ì„¸ë¶€ ê²°ê³¼ë¥¼ ê²°ì •"""
    voice_type_map = {
        ('high_energy', 'dynamic_tone'): "í™œê¸°ì°¬ ì—ë„ˆì§€ ë³´ì´ìŠ¤",
        ('high_pitch', 'clear_voice'): "ë§‘ê³  ì²­ëŸ‰í•œ í¬ë¦¬ìŠ¤íƒˆ ë³´ì´ìŠ¤",
        ('low_pitch', 'stable_tone'): "ê¹Šê³  ì¹´ë¦¬ìŠ¤ë§ˆ ìˆëŠ” ë² ì´ìŠ¤ ë³´ì´ìŠ¤",
        ('low_energy', 'soft_voice'): "ì°¨ë¶„í•˜ê³  ì†ì‚­ì´ëŠ” ìœ„ìŠ¤í¼ ë³´ì´ìŠ¤",
        ('clear_voice',): "ë”°ëœ»í•˜ê³  ë¶€ë“œëŸ¬ìš´ í—ˆë‹ˆ ë³´ì´ìŠ¤",
        ('husky_voice', 'high_energy'): "íŒŒì›Œí’€í•˜ê³  ê°•ë ¬í•œ ì¬ë” ë³´ì´ìŠ¤",
        ('mid_energy', 'dynamic_tone'): "ê°ì„±ì ì´ê³  ëª½í™˜ì ì¸ ë¬¸ë¼ì´íŠ¸ ë³´ì´ìŠ¤",
    }
    voice_type = "ì‹œì›í•˜ê³  ê¹”ë”í•œ ë¯¼íŠ¸ ë³´ì´ìŠ¤"
    for p_set, v_type in voice_type_map.items():
        if all(p in profile for p in p_set):
            voice_type = v_type
            break

    animal_type_map = {
        ('high_pitch', 'dynamic_tone'): "í† ë¼ìƒ",
        ('high_pitch', 'low_energy'): "ê³ ì–‘ì´ìƒ",
        ('high_pitch', 'high_energy'): "ê°•ì•„ì§€ìƒ",
        ('low_pitch', 'husky_voice'): "ëŠ‘ëŒ€ìƒ",
        ('low_pitch', 'high_energy'): "ì‚¬ììƒ",
        ('mid_pitch', 'stable_tone'): "ê³°ìƒ",
        ('mid_pitch', 'dynamic_tone'): "ì—¬ìš°ìƒ"
    }
    animal = "í–„ìŠ¤í„°ìƒ"
    for p_set, a_type in animal_type_map.items():
        if all(p in profile for p in p_set):
            animal = a_type
            break
    animal_type = next(
        (item for item in voice_analysis_data["animalTypes"] if item["type"] == animal),
        random.choice(voice_analysis_data["animalTypes"])
    )

    personality_type_map = {
        ('high_energy', 'dynamic_tone'): "ë¶„ìœ„ê¸° ë©”ì´ì»¤í˜•",
        ('low_energy', 'stable_tone'): "ê¹Šê³  ì°¨ë¶„í•œ ì•ˆì •í˜•",
        ('low_pitch', 'stable_tone'): "íƒ€ê³ ë‚œ ë¦¬ë”í˜•",
        ('high_pitch', 'dynamic_tone'): "ì°½ì˜ì ì¸ ì•„í‹°ìŠ¤íŠ¸í˜•",
        ('high_energy', 'clear_voice'): "í™œë™ì ì¸ ìŠ¤í¬ì¸ í˜•",
        ('husky_voice', 'dynamic_tone'): "ìœ ë¨¸ëŸ¬ìŠ¤í•œ ì¬ë¯¸í˜•",
        ('clear_voice', 'stable_tone'): "ì§€ì ì´ê³  ë¶„ì„ì ì¸ í˜•",
    }
    personality = "ë”°ëœ»í•œ ê°ì„±í˜•"
    for p_set, p_type in personality_type_map.items():
        if all(p in profile for p in p_set):
            personality = p_type
            break
    personality_type = next(
        (item for item in voice_analysis_data["personalityTypes"] if item["type"] == personality),
        random.choice(voice_analysis_data["personalityTypes"])
    )

    # â–¶ ê°€ì¤‘ì¹˜ ìŠ¤ì½”ì–´ ê¸°ë°˜ ì§ì—… ì„ ì •
    if features is not None:
        job, job_candidates = select_job_with_scores(profile, features, audio_bytes)
    else:
        job = "ë¼ë””ì˜¤ DJ"
        job_candidates = [{"job": "ë¼ë””ì˜¤ DJ", "score": 0.0}]

    tag_map = {
        ('low_energy', 'soft_voice'): "ASMR ì²œì¬",
        ('clear_voice', 'high_pitch'): "ê·€í˜¸ê°• ì£¼ì¸ê³µ",
        ('low_pitch', 'stable_tone'): "ì¹´ë¦¬ìŠ¤ë§ˆ í­ë°œ",
        ('soft_voice', 'clear_voice'): "ëª©ì†Œë¦¬ ê¿€",
        ('high_energy', 'dynamic_tone'): "ë§¤ë ¥ ë°œì‚°ê¸°",
        ('husky_voice', 'low_pitch'): "ë³´ì´ìŠ¤ í”¼ì…”",
    }
    tag = "íë§ ë³´ì´ìŠ¤"
    for p_set, t_type in tag_map.items():
        if all(p in profile for p in p_set):
            tag = t_type
            break

    color_map = {
        ('high_pitch', 'clear_voice'): "ì‚¬íŒŒì´ì–´ ë¸”ë£¨",
        ('high_pitch', 'high_energy'): "ê³¨ë“  ì˜ë¡œìš°",
        ('low_pitch', 'stable_tone'): "ì˜¤ë‹‰ìŠ¤ ë¸”ë™",
        ('low_pitch', 'husky_voice'): "ë£¨ë¹„ ë ˆë“œ",
        ('soft_voice', 'mid_pitch'): "ë¡œì¦ˆ ê³¨ë“œ",
        ('clear_voice', 'stable_tone'): "ì—ë©”ë„ë“œ ê·¸ë¦°",
        ('dynamic_tone', 'mid_energy'): "ì•„ë©”ì‹œìŠ¤íŠ¸ í¼í”Œ",
    }
    color = "ì‹¤ë²„ í™”ì´íŠ¸"
    for p_set, c_type in color_map.items():
        if all(p in profile for p in p_set):
            color = c_type
            break

    return {
        "voice_type": voice_type,
        "animal_type": {k: v for k, v in animal_type.items() if k not in ['id']},
        "personality_type": {k: v for k, v in personality_type.items() if k not in ['id']},
        "compatibility_job": job,
        "job_candidates": job_candidates,   # ìƒìœ„ 3ê°œ í›„ë³´ ì œê³µ
        "special_tag": tag,
        "voice_color": color,
    }

# --- ë ˆì´ë” ì •ê·œí™” (NaN ì•ˆì „) ---

def normalize_features_for_radar(features):
    # pitch: 80~250Hz â†’ 0~100
    pitch_score = np.nan_to_num((features["pitch"] - 80) / (250 - 80) * 100, nan=50.0)
    # energy: 0~1 â†’ 0~100
    energy_score = np.nan_to_num(features["energy"] * 100, nan=50.0)
    # speaking rate(tempo ìë¦¬): 70~180 â†’ 0~100
    tempo_score = np.nan_to_num((features["tempo"] - 70) / (180 - 70) * 100, nan=50.0)
    # HNR â†’ ì™„ë§Œ ìŠ¤ì¼€ì¼ (2.5*dB + 50)
    clearness_score = np.nan_to_num(features['harmonicity'] * 2.5 + 50, nan=50.0)
    # ì•ˆì •ê°: ì„¼íŠ¸ í‘œì¤€í¸ì°¨ ì‚¬ìš© ì‹œ ë” íƒ€ë‹¹ (ì‘ì„ìˆ˜ë¡ ì•ˆì •)
    if "pitch_std_cents" in features:
        c = float(features["pitch_std_cents"])
        # 40â†’90, 120â†’50, 200â†’10 ë¡œ ë§¤í•‘(êµ¬ê°„ ì™¸ëŠ” ì–‘ëìœ¼ë¡œ í¬í™”)
        stability_score = np.interp(c, [40, 120, 200], [90, 50, 10])
    else:
        # Hz í‘œì¤€í¸ì°¨ì¼ ë•Œë„ ëŒ€ëµì  ë³´ì •(í”¼ì¹˜ê°€ ë†’ì„ìˆ˜ë¡ ìœ ë¦¬í•˜ë¯€ë¡œ ë³´ìˆ˜ì ìœ¼ë¡œ)
        h = float(features["pitch_std"])
        stability_score = np.interp(h, [5, 20, 40], [90, 50, 10])

    stability_score = float(np.clip(stability_score, 10, 100))

    return [
        {"feature": "ë†’ì´", "value": int(np.clip(pitch_score, 10, 100))},
        {"feature": "ì—ë„ˆì§€", "value": int(np.clip(energy_score, 10, 100))},
        {"feature": "ì†ë„", "value": int(np.clip(tempo_score, 10, 100))},
        {"feature": "ë§‘ìŒ", "value": int(np.clip(clearness_score, 10, 100))},
        {"feature": "ì•ˆì •ê°", "value": int(np.clip(stability_score, 10, 100))},
    ]

def calculate_attraction_score(radar_data):
    values = [item['value'] for item in radar_data]
    average_score = np.mean(values)
    std_dev = np.std(values)
    balance_bonus = max(0, 25 - std_dev)
    ideal_range_bonus = 10 if all(40 <= v <= 85 for v in values) else 0
    final_score = 60 + (average_score - 50) * 0.5 + balance_bonus + ideal_range_bonus
    return min(99, max(60, int(final_score)))

# --- í’ˆì§ˆ ì§„ë‹¨ ---

def estimate_snr(y):
    rms = librosa.feature.rms(y=y)[0]
    med = np.median(rms)
    noise = np.percentile(rms, 10)
    return float(20 * np.log10((med + 1e-8) / (noise + 1e-8)))

def clipping_ratio(y):
    return float(np.mean(np.abs(y) > 0.98))

def choose_deterministic(seq, audio_bytes):
    if not seq:
        return None
    h = int(hashlib.md5(audio_bytes).hexdigest(), 16)
    return seq[h % len(seq)]

# --- ì—”ë“œí¬ì¸íŠ¸ ---

@app.post("/api/analyze")
async def analyze_voice(gender: str = Form(...), audio: UploadFile = File(...)):
    try:
        # content-type ê°€ë“œ(ë¸Œë¼ìš°ì € ì—…ë¡œë“œëŠ” ì¢…ì¢… application/octet-stream)
        if audio.content_type and not (
            audio.content_type.startswith("audio/") or audio.content_type == "application/octet-stream"
        ):
            raise HTTPException(status_code=400, detail=f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì½˜í…ì¸  íƒ€ì…ì…ë‹ˆë‹¤: {audio.content_type}")

        audio_bytes = await audio.read()
        if not audio_bytes:
            raise HTTPException(status_code=400, detail="ì˜¤ë””ì˜¤ íŒŒì¼ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
        if len(audio_bytes) > MAX_BYTES:
            raise HTTPException(status_code=400, detail=f"íŒŒì¼ì´ ë„ˆë¬´ í½ë‹ˆë‹¤(â‰¤ {MAX_BYTES // (1024*1024)}MB).")

        # pydub ë¡œë“œ
        try:
            sound = AudioSegment.from_file(io.BytesIO(audio_bytes))
        except Exception:
            raise HTTPException(status_code=400, detail="ì˜¤ë””ì˜¤ í¬ë§·ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. WAV/MP3 ë“± í‘œì¤€ í¬ë§·ì„ ì‚¬ìš©í•´ ì£¼ì„¸ìš”.")

        # ëª¨ë…¸ ë³€í™˜
        if sound.channels > 1:
            sound = sound.set_channels(1)

        # float32 íŒŒí˜•
        samples = np.array(sound.get_array_of_samples()).astype(np.float32) / (2 ** (sound.sample_width * 8 - 1))

        # ë¦¬ìƒ˜í”Œ
        target_sr = 22050
        y = librosa.resample(y=samples, orig_sr=sound.frame_rate, target_sr=target_sr)
        sr = target_sr

        # ì „ì²˜ë¦¬
        y = trim_and_normalize(y, sr)
        if len(y) < int(MIN_SEC * sr):
            raise HTTPException(status_code=400, detail=f"ì˜¤ë””ì˜¤ ê¸¸ì´ê°€ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤(â‰¥{MIN_SEC:.1f}ì´ˆ í•„ìš”).")
        if len(y) > int(MAX_SEC * sr):
            y = y[:int(MAX_SEC * sr)]

        # íŠ¹ì„± ì¶”ì¶œ (pyin 1íšŒ)
        pitch_med, pitch_std_hz, pitch_std_cents = extract_pitch_stats(y, sr)
        energy = analyze_energy(y)                    # 0~1
        speaking_rate = analyze_speaking_rate(y, sr)  # 70~180
        hnr = analyze_harmonicity(y)                  # -20~20 (í´ë¦¬í•‘)
        spec_cent = analyze_spectral_centroid(y, sr)

        features = {
            "pitch": pitch_med,
            "energy": energy,
            "tempo": speaking_rate,              # ê¸°ì¡´ í‚¤ ìœ ì§€(UI í˜¸í™˜)
            "pitch_std": pitch_std_hz,
            "pitch_std_cents": pitch_std_cents,
            "harmonicity": hnr
        }

        voice_profile = get_voice_profile(features)
        detailed_results = analyze_details_based_on_profile(voice_profile, features, audio_bytes)

        # ë‚˜ì´ëŒ€ ì¶”ì •
        if gender == 'female':
            age_key = get_age_key_female(features["pitch"], spec_cent, features["energy"])
        else:  # male or other
            age_key = get_age_key_male(features["pitch"], spec_cent, features["energy"])

        age_info = voice_analysis_data["age_groups"].get(age_key, voice_analysis_data["age_groups"]["30s_early"])

        # ë ˆì´ë”/ìŠ¤ì½”ì–´
        radar_data = normalize_features_for_radar(features)
        attraction_score = calculate_attraction_score(radar_data)

        # ìœ ë‹ˆí¬ë‹ˆìŠ¤(ì•ˆì „ ê³„ì‚°)
        uniqueness_score = int(np.clip(
            65
            + 0.20 * np.nan_to_num(features.get("pitch_std_cents", 80.0))
            + 25.0 * abs(np.nan_to_num(features["energy"]) - 0.5)
            + 1.5 * abs(np.nan_to_num(features["harmonicity"]) - 5.0),
            60, 99
        ))

        # ì…ë ¥ í’ˆì§ˆ ê²½ê³ 
        snr = estimate_snr(y)
        clip = clipping_ratio(y)
        voiced_ratio = float(sum((e - s) for s, e in librosa.effects.split(y, top_db=30)) / len(y))
        warnings = []
        if snr < 10:
            warnings.append("ì£¼ë³€ ì†ŒìŒì´ ì»¤ì„œ ì •í™•ë„ê°€ ë–¨ì–´ì§ˆ ìˆ˜ ìˆì–´ìš”.")
        if clip > 0.02:
            warnings.append("ì…ë ¥ì´ í´ë¦¬í•‘ë˜ì—ˆìŠµë‹ˆë‹¤. ë§ˆì´í¬ ì…ë ¥ ë ˆë²¨ì„ ë‚®ì¶°ì£¼ì„¸ìš”.")
        if voiced_ratio < 0.4:
            warnings.append("ë¬´ìŒ êµ¬ê°„ì´ ë§ìŠµë‹ˆë‹¤. 2ì´ˆ ì´ìƒ ë˜ë°•ë˜ë°• ë§í•´ì£¼ì„¸ìš”.")

        # ê²°ì •ì  ìœ ë¨¸ ì„ íƒ(ê°™ì€ íŒŒì¼ â†’ ê°™ì€ ë¬¸êµ¬)
        humor = choose_deterministic(age_info["humor"], audio_bytes)

        result = {
            "version": API_VERSION,
            "age_range": age_info["range"],
            "humor_quote": humor,
            "attraction_score": attraction_score,
            "uniqueness_score": uniqueness_score,
            "radar_data": radar_data,
            "warnings": warnings,
            **detailed_results
        }

        return JSONResponse(content=result)

    except HTTPException:
        raise
    except Exception as e:
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"An error occurred during analysis: {str(e)}")

@app.get("/")
async def root():
    return {"message": "Voice Age API is running!", "version": API_VERSION}

@app.get("/healthz")
async def healthz():
    return {"status": "ok", "version": API_VERSION}
