# api/analyze.py

from fastapi import FastAPI, File, UploadFile, HTTPException, Form
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
import librosa
import numpy as np
import io
from pydub import AudioSegment
import random
import traceback
import hashlib

API_VERSION = "1.4.0" # CHANGED: ë²„ì „ ì—…ë°ì´íŠ¸

app = FastAPI()

# CORS
origins = [
    "http://localhost:5173",
    "http://127.0.0.1:5173",
    "https://voice-age-app.vercel.app"
]

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- ì œí•œ/ê°€ë“œ ìƒìˆ˜ ---
MIN_SEC = 0.5
MAX_SEC = 12
MAX_BYTES = 10 * 1024 * 1024  # 10MB

# --- ë°ì´í„° í’€ ---
voice_analysis_data = {
    "age_groups": {
        "10s": {"range": "10ëŒ€", "humor": ["ëª©ì†Œë¦¬ì—ì„œ 'ì—„ë§ˆ ìš©ëˆ ì˜¬ë ¤ë‹¬ë¼'ëŠ” ê°„ì ˆí•¨ì´ ëŠê»´ì ¸ìš”! ğŸŒ¸", "ë¼ë©´ ë“ì´ëŠ” ì†Œë¦¬ë§Œ ë“¤ì–´ë„ ë‹¬ë ¤ì˜¬ ê²ƒ ê°™ì€ ëª©ì†Œë¦¬! âš¡", "ë°¤ 12ì‹œì— 'ìˆ™ì œ ì–¸ì œ í•˜ì§€?' í•˜ëŠ” ëª©ì†Œë¦¬ë„¤ìš”! ğŸ“±", "ì²­ì¶˜ ë“œë¼ë§ˆì—ì„œ 'ì•¼, ë„ˆ ì¢‹ì•„í•´' ê³ ë°±í•  ëª©ì†Œë¦¬! ğŸ­", "ìƒˆë¡œ ë‚˜ì˜¨ ì¤„ì„ë§ì„ ì¼ì£¼ì¼ ë§Œì— ë§ˆìŠ¤í„°í•  ê²ƒ ê°™ì•„ìš”!", "ì—ë„ˆì§€ ë“œë§í¬ê°€ ëª©ì†Œë¦¬ë¡œ ë³€í•œ ëŠë‚Œ!"]},
        "20s_early": {"range": "20ëŒ€ ì´ˆë°˜", "humor": ["ëŒ€í•™ ê³¼ì œ ë§ˆê° 2ì‹œê°„ ì „ì˜ ì ˆë§ê³¼ í¬ë§ì´ ê³µì¡´í•˜ëŠ” ëª©ì†Œë¦¬! ğŸ“", "ë°¤ìƒˆ íŒ€í”Œí•˜ê³  'ì´ë²ˆì—” ì§„ì§œ A+ ë°›ì„ ê±°ì•¼' í•˜ëŠ” ëª©ì†Œë¦¬!", "MTì—ì„œ 'ìš°ë¦¬ ê³¼ ìµœê³ !' ì™¸ì¹  ëª©ì†Œë¦¬ì—ìš”!", "'ì˜¤ëŠ˜ ë­ ë¨¹ì§€?'ê°€ ì¸ìƒ ìµœëŒ€ ê³ ë¯¼ì¸ ëª©ì†Œë¦¬!", "ê°œê°•íŒŒí‹° ì£¼ìµœì ëª©ì†Œë¦¬ë„¤ìš”!", "ì¹œêµ¬ ë²ˆí˜¸ ë¬¼ì–´ë´ë‹¬ë¼ê³  ë¶€íƒë°›ì„ ëª©ì†Œë¦¬!"]},
        "20s_late": {"range": "20ëŒ€ í›„ë°˜", "humor": ["ì´ì œ ë§‰ 'ì–´ë¥¸'ì´ë¼ëŠ” ê°€ë©´ì„ ì“°ê¸° ì‹œì‘í•œ ëª©ì†Œë¦¬! ğŸº", "í‡´ê·¼ê¸¸ì— 'ì˜¤ëŠ˜ë„ ê³ ìƒí–ˆë‹¤' í˜¼ì£ë§í•  ëª©ì†Œë¦¬ë„¤ìš”!", "ì²« ì›”ê¸‰ìœ¼ë¡œ 'ì´ì œì•¼ ì‚¬ëŒ ëë‹¤' ëŠë¼ëŠ” ëª©ì†Œë¦¬!", "ì£¼ë§ ì•½ì† ì—†ìœ¼ë©´ ì¸ì‹¸ ìê²© ë°•íƒˆë‹¹í•  ê²ƒ ê°™ì€ ëª©ì†Œë¦¬!", "ì—°ì• í•  ë•Œ ê°€ì¥ ì„¤ë ˆì§€ë§Œ í˜„ì‹¤ì€ ì†”ë¡œì¸ ëª©ì†Œë¦¬ ğŸ’•", "ë…ë¦½ í›„ 'ì§‘ì—ì„œ ì†ì˜·ë§Œ ì…ê³  ë‹¤ë‹ˆëŠ” ììœ 'ë¥¼ ë§Œë½í•˜ëŠ” ëª©ì†Œë¦¬!"]},
        "30s_early": {"range": "30ëŒ€ ì´ˆë°˜", "humor": ["ì•ˆì •ê°ì€ ìˆëŠ”ë° ì—¬ì „íˆ ê²Œì„ ë°¤ìƒˆëŠ” ëª©ì†Œë¦¬ì˜ˆìš”.", "ë„·í”Œë¦­ìŠ¤ ì •ì£¼í–‰ì´ ìµœê³ ì˜ íë§ì´ë¼ê³  í™•ì‹ í•˜ëŠ” ëª©ì†Œë¦¬!", "'ì•„, í—ˆë¦¬ì•¼...' ì²« ì‹ ìŒì†Œë¦¬ë¥¼ ë‚¸ ëª©ì†Œë¦¬!", "íšŒì‚¬ì—ì„œ 'ë¯¿ê³  ë§¡ê¸¸ ìˆ˜ ìˆëŠ”' ëª©ì†Œë¦¬ ğŸ’¼", "ê²°í˜¼ì‹ ì¶•ì‚¬ì—ì„œ ì›ƒìŒê³¼ ê°ë™ì„ ë™ì‹œì— ì¤„ ëª©ì†Œë¦¬!", "ì»¤í”¼ ì—†ìœ¼ë©´ ì¢€ë¹„ê°€ ë˜ëŠ” ëª©ì†Œë¦¬ â˜•"]},
        "30s_late": {"range": "30ëŒ€ í›„ë°˜", "humor": ["ê¹Šì´ëŠ” ìˆëŠ”ë° ì•„ì§ ìœ íŠœë¸Œ ì•Œê³ ë¦¬ì¦˜ì— ë‹¹í•˜ëŠ” ëª©ì†Œë¦¬! ğŸ’°", "ì¬í…Œí¬ ìœ íŠœë¸Œ ë³´ë©´ì„œ 'ë‚˜ë„ ë¶€ì ë  ìˆ˜ ìˆì–´' í•˜ëŠ” ëª©ì†Œë¦¬!", "ìœ¡ì•„ í˜„ì‹¤ì— ì¹˜ì—¬ë„ ì•„ì´ ì•ì—ì„  ì²œì‚¬ê°€ ë˜ëŠ” ëª©ì†Œë¦¬ ğŸ‘¶", "ìº í•‘ ê°€ì„œ 'ìì—°ì´ ìµœê³ ì•¼' í•˜ì§€ë§Œ ì™€ì´íŒŒì´ ì°¾ëŠ” ëª©ì†Œë¦¬!", "ì¸ìƒ í™©ê¸ˆê¸°ë¼ì§€ë§Œ ì²´ë ¥ì€ ì´ë¯¸ í•˜í–¥ê³¡ì„ ì¸ ëª©ì†Œë¦¬! âœ¨", "'ì§‘ì´ ì²œêµ­'ì´ë¼ëŠ” ì§„ë¦¬ë¥¼ ê¹¨ë‹¬ì€ ëª©ì†Œë¦¬!"]},
        "40s_early": {"range": "40ëŒ€ ì´ˆë°˜", "humor": ["í¸ì•ˆí•˜ì§€ë§Œ ê°‘ìê¸° 'ìš”ì¦˜ ì• ë“¤ì€...' í•˜ê³  ì‹¶ì–´ì§€ëŠ” ëª©ì†Œë¦¬!", "ì™€ì¸ ë§ˆì‹œë©´ì„œ 'ì¸ìƒì„ ë…¼í•˜ê³ ' ì‹¶ì–´ì§€ëŠ” ëª©ì†Œë¦¬ ğŸ·", "í›„ë°°ë“¤ì—ê²Œ ë°¥ ì‚¬ì£¼ë©´ì„œ 'ë‚´ ì Šì—ˆì„ ë•ŒëŠ”' ì‹œì „í•  ëª©ì†Œë¦¬!", "ì•„ì´ ìˆ™ì œ ë„ì™€ì£¼ë‹¤ê°€ 'ì´ê²Œ ë­ì•¼?' í•  ëª©ì†Œë¦¬ ğŸ“", "ê²½í—˜ë‹´ì´ ë ˆì „ë“œê°€ ëœ ëª©ì†Œë¦¬ ğŸ“š", "ê³¨í”„ ì¹˜ë©´ì„œ 'ìŠ¤íŠ¸ë ˆìŠ¤ í‘¸ëŠ”' ëª©ì†Œë¦¬!"]},
        "40s_late": {"range": "40ëŒ€ í›„ë°˜", "humor": ["ì§€í˜œë¡­ì§€ë§Œ ì•„ì§ ìŠ¤ë§ˆíŠ¸í° ê¸°ëŠ¥ì„ ë‹¤ ëª¨ë¥´ëŠ” ëª©ì†Œë¦¬!", "'ë‚´ê°€ ë„ˆ ë•ŒëŠ”...' ì „ì„¤ì˜ ì‹œì‘ì„ ì•Œë¦¬ëŠ” ëª©ì†Œë¦¬!", "ì¸ìƒì˜ ë‹¨ë§›ì„ ì•„ëŠ” ë™ì‹œì— ì“´ë§›ë„ ì•„ëŠ” ëª©ì†Œë¦¬!", "ë‹¤í ë³´ë©´ì„œ 'ì—­ì‹œ ì˜›ë‚ ì´ ì¢‹ì•˜ì–´' í•  ëª©ì†Œë¦¬!", "ê°€ì¡±ì—¬í–‰ ê³„íš ì„¸ìš°ëŠ” ê²Œ ì·¨ë¯¸ê°€ ëœ ëª©ì†Œë¦¬!", "ì¹œêµ¬ ëª¨ì„ì—ì„œ 'ê±´ê°•ì´ ìµœê³ ì•¼' ì™¸ì¹˜ëŠ” ëª©ì†Œë¦¬!"]},
        "50s_plus": {"range": "50ëŒ€ ì´ìƒ", "humor": ["ëª¨ë“  ê²ƒì„ ë‹¤ ê²ªì–´ë³¸ 'ì¸ìƒ ê³ ìˆ˜'ì˜ ì—¬ìœ ë¡œìš´ ëª©ì†Œë¦¬!", "ì°¨ í•œ ì”ì— 'ì¸ìƒ ì² í•™'ì„ ë‹´ì•„ë‚¼ ìˆ˜ ìˆëŠ” ëª©ì†Œë¦¬ ğŸµ", "'ì´ì œì•¼ ì§„ì§œ ë‚´ ì¸ìƒì´ ì‹œì‘ì´ì•¼' í•˜ëŠ” ëª©ì†Œë¦¬ ğŸ­", "ì†ì ì†ë…€ì—ê²Œ 'ì˜›ë‚ ì— í• ì•„ë²„ì§€ëŠ”...' ì‹œì „í•˜ëŠ” ëª©ì†Œë¦¬!", "ë“±ì‚°ë³µì´ ì¼ìƒë³µì´ ëœ ëª©ì†Œë¦¬ ğŸ”ï¸", "í…ƒë°­ì—ì„œ 'ë‚´ê°€ ê¸°ë¥¸ ë°°ì¶”ê°€ ìµœê³ ì•¼' í•˜ëŠ” ëª©ì†Œë¦¬!"]},
    },
    # CHANGED: ë™ë¬¼ìƒ ì œê±°
    "personalityTypes": [ # CHANGED: "ëª©ì†Œë¦¬ ì„±ê²© ìœ í˜•"ìœ¼ë¡œ ë³€ê²½í•˜ê³  ì„¤ëª… ì¶”ê°€
        {"id": "leader", "type": "íƒ€ê³ ë‚œ ë¦¬ë”í˜•", "emoji": "ğŸ‘‘", "color": "#f59e0b", "desc": "ë‚®ê³  ì•ˆì •ì ì¸ í†¤ì—ì„œ ë‚˜ì˜¤ëŠ” ê°•í•œ ì‹ ë¢°ê°ê³¼ ì¹´ë¦¬ìŠ¤ë§ˆê°€ ë‹ë³´ì…ë‹ˆë‹¤."},
        {"id": "emotional", "type": "ë”°ëœ»í•œ ê°ì„±í˜•", "emoji": "ğŸ’", "color": "#ec4899", "desc": "ë¶€ë“œëŸ½ê³  ì˜¨í™”í•œ ìŒìƒ‰ìœ¼ë¡œ, ë“£ëŠ” ì‚¬ëŒì˜ ë§ˆìŒì„ í¸ì•ˆí•˜ê²Œ ë§Œë“œëŠ” ê³µê° ëŠ¥ë ¥ì´ ë›°ì–´ë‚©ë‹ˆë‹¤."},
        {"id": "maker", "type": "ë¶„ìœ„ê¸° ë©”ì´ì»¤í˜•", "emoji": "ğŸ‰", "color": "#8b5cf6", "desc": "ë†’ì€ ì—ë„ˆì§€ì™€ ë‹¤ì±„ë¡œìš´ ì–µì–‘ìœ¼ë¡œ ì£¼ë³€ ë¶„ìœ„ê¸°ë¥¼ ë°ê³  í™œê¸°ì°¨ê²Œ ì´ëŒì–´ê°‘ë‹ˆë‹¤."},
        {"id": "stable", "type": "ê¹Šê³  ì°¨ë¶„í•œ ì•ˆì •í˜•", "emoji": "ğŸ§˜", "color": "#06b6d4", "desc": "ë³€í™”ê°€ ì ê³  ì¼ì •í•œ í†¤ì„ ìœ ì§€í•˜ì—¬, ì§„ì¤‘í•˜ê³  ì‹ ì¤‘í•œ ì¸ìƒì„ ì¤ë‹ˆë‹¤."},
        {"id": "humorous", "type": "ìœ ë¨¸ëŸ¬ìŠ¤í•œ ì¬ë¯¸í˜•", "emoji": "ğŸ˜„", "color": "#10b981", "desc": "ì˜ˆìƒì¹˜ ëª»í•œ í†¤ ë³€í™”ì™€ ì¬ì¹˜ ìˆëŠ” ìŒìƒ‰ìœ¼ë¡œ ëŒ€í™”ì— í™œë ¥ì„ ë¶ˆì–´ë„£ìŠµë‹ˆë‹¤."},
        {"id": "artist", "type": "ì°½ì˜ì ì¸ ì•„í‹°ìŠ¤íŠ¸í˜•", "emoji": "ğŸ¨", "color": "#f97316", "desc": "ë„“ì€ ìŒì—­ëŒ€ì™€ í‘œí˜„ë ¥ì„ í†µí•´ ìì‹ ë§Œì˜ ë…íŠ¹í•œ ê°œì„±ì„ ëª©ì†Œë¦¬ë¡œ í‘œí˜„í•©ë‹ˆë‹¤."},
        {"id": "analytical", "type": "ì§€ì ì´ê³  ë¶„ì„ì ì¸ í˜•", "emoji": "ğŸ¤“", "color": "#6366f1", "desc": "ëª…í™•í•˜ê³  ë˜ë ·í•œ ë°œìŒìœ¼ë¡œ ë…¼ë¦¬ ì •ì—°í•˜ê²Œ ìì‹ ì˜ ìƒê°ì„ ì „ë‹¬í•˜ëŠ” ë° ëŠ¥ìˆ™í•©ë‹ˆë‹¤."},
        {"id": 'active', 'type': 'í™œë™ì ì¸ ìŠ¤í¬ì¸ í˜•', 'emoji': 'ğŸƒ', 'color': '#ef4444', 'desc': 'ë¹ ë¥´ê³  í˜ ìˆëŠ” ëª©ì†Œë¦¬ë¡œ, ë„˜ì¹˜ëŠ” ì—´ì •ê³¼ ì—ë„ˆì§€ë¥¼ ê·¸ëŒ€ë¡œ ë³´ì—¬ì¤ë‹ˆë‹¤.'},
    ],
    # CHANGED: ë³´ì´ìŠ¤ íƒ€ì…ì— ì„¤ëª… ì¶”ê°€
    "voiceTypes": [
        {"id": "energy", "type": "í™œê¸°ì°¬ ì—ë„ˆì§€ ë³´ì´ìŠ¤", "desc": "ë†’ì€ ì—ë„ˆì§€ì™€ ë‹¤ì±„ë¡œìš´ í†¤ ë³€í™”ë¡œ ìƒë™ê° ë„˜ì¹˜ëŠ” ë¶„ìœ„ê¸°ë¥¼ ë§Œë“­ë‹ˆë‹¤.", "profile_set": ('high_energy', 'dynamic_tone')},
        {"id": "crystal", "type": "ë§‘ê³  ì²­ëŸ‰í•œ í¬ë¦¬ìŠ¤íƒˆ ë³´ì´ìŠ¤", "desc": "ë†’ê³  ê¹¨ë—í•œ ìŒìƒ‰ì´ íŠ¹ì§•ìœ¼ë¡œ, ìˆ˜ì •ì²˜ëŸ¼ íˆ¬ëª…í•˜ê³  ìƒì¾Œí•œ ëŠë‚Œì„ ì¤ë‹ˆë‹¤.", "profile_set": ('high_pitch', 'clear_voice')},
        {"id": "base", "type": "ê¹Šê³  ì¹´ë¦¬ìŠ¤ë§ˆ ìˆëŠ” ë² ì´ìŠ¤ ë³´ì´ìŠ¤", "desc": "ë‚®ê³  ì•ˆì •ì ì¸ í†¤ì´ ê°•í•œ ì‹ ë¢°ê°ì„ ì£¼ë©°, ë¬µì§í•œ ì¡´ì¬ê°ì„ ë“œëŸ¬ëƒ…ë‹ˆë‹¤.", "profile_set": ('low_pitch', 'stable_tone')},
        {"id": "whisper", "type": "ì°¨ë¶„í•˜ê³  ì†ì‚­ì´ëŠ” ìœ„ìŠ¤í¼ ë³´ì´ìŠ¤", "desc": "ë‚®ì€ ì—ë„ˆì§€ì™€ ë¶€ë“œëŸ¬ìš´ ìŒìƒ‰ìœ¼ë¡œ, ë¹„ë°€ ì´ì•¼ê¸°ë¥¼ ë‚˜ëˆ„ë“¯ ì¹œë°€í•œ ë¶„ìœ„ê¸°ë¥¼ í˜•ì„±í•©ë‹ˆë‹¤.", "profile_set": ('low_energy', 'soft_voice')},
        {"id": "honey", "type": "ë”°ëœ»í•˜ê³  ë¶€ë“œëŸ¬ìš´ í—ˆë‹ˆ ë³´ì´ìŠ¤", "desc": "ê¿€ì²˜ëŸ¼ ë‹¬ì½¤í•˜ê³  ë§¤ë„ëŸ¬ìš´ ìŒìƒ‰ìœ¼ë¡œ, ë“£ëŠ” ì‚¬ëŒì˜ ë§ˆìŒì„ í¸ì•ˆí•˜ê²Œ ë…¹ì—¬ì¤ë‹ˆë‹¤.", "profile_set": ('clear_voice',)},
        {"id": "thunder", "type": "íŒŒì›Œí’€í•˜ê³  ê°•ë ¬í•œ ì¬ë” ë³´ì´ìŠ¤", "desc": "ë‹¤ì†Œ ê±°ì¹ ì§€ë§Œ í˜ ìˆëŠ” í†¤ì´ í­ë°œì ì¸ ì—ë„ˆì§€ë¥¼ ì „ë‹¬í•˜ë©° ê°•í•œ ì¸ìƒì„ ë‚¨ê¹ë‹ˆë‹¤.", "profile_set": ('husky_voice', 'high_energy')},
        {"id": "moonlight", "type": "ê°ì„±ì ì´ê³  ëª½í™˜ì ì¸ ë¬¸ë¼ì´íŠ¸ ë³´ì´ìŠ¤", "desc": "ë‹¤ì–‘í•œ í†¤ ë³€í™”ì™€ ê°ì„±ì ì¸ í‘œí˜„ë ¥ìœ¼ë¡œ ë‹¬ë¹›ì²˜ëŸ¼ ì‹ ë¹„ë¡­ê³  ë¹ ì ¸ë“œëŠ” ë§¤ë ¥ì´ ìˆìŠµë‹ˆë‹¤.", "profile_set": ('mid_energy', 'dynamic_tone')},
        {"id": "mint", "type": "ì‹œì›í•˜ê³  ê¹”ë”í•œ ë¯¼íŠ¸ ë³´ì´ìŠ¤", "desc": "êµ°ë”ë”ê¸° ì—†ì´ ê¹”ë”í•˜ê³  ì •ëˆëœ í†¤ìœ¼ë¡œ, ì‹œì›í•˜ê³  ìƒì¾Œí•œ ì¸ìƒì„ ì¤ë‹ˆë‹¤.", "profile_set": ()} # Default
    ],
    # CHANGED: ì§ì—… ì¶”ì²œ ì´ìœ  ì¶”ê°€
    "jobReasons": {
        "ì•„ë‚˜ìš´ì„œ": "ê¹¨ë—í•˜ê³  ì•ˆì •ì ì¸ í†¤ì´ ì •í™•í•œ ì •ë³´ ì „ë‹¬ì— ì‹ ë¢°ê°ì„ ë”í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.",
        "MC": "ë†’ì€ ì—ë„ˆì§€ì™€ ë‹¤ì´ë‚˜ë¯¹í•œ í†¤ ë³€í™”ë¡œ ëŒ€ì¤‘ì˜ ì´ëª©ì„ ë„ëŠ” ëŠ¥ë ¥ì´ íƒì›”í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.",
        "ì˜¤ë””ì˜¤ë¶ ë‚´ë ˆì´í„°": "ì°¨ë¶„í•˜ê³  ë¶€ë“œëŸ¬ìš´ ëª©ì†Œë¦¬ê°€ ë“£ëŠ” ì´ë¥¼ ì´ì•¼ê¸°ì— ê¹Šì´ ëª°ì…í•˜ê²Œ ë§Œë“¤ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.",
        "ë°°ìš°": "ëª©ì†Œë¦¬ì˜ ê°ì • í‘œí˜„ ë²”ìœ„ê°€ ë„“ì–´ ë‹¤ì–‘í•œ ì—­í• ì„ ì†Œí™”í•  ìˆ˜ ìˆëŠ” ì ì¬ë ¥ì´ ë‹ë³´ì´ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.",
        "ìœ íŠœë²„": "ì—ë„ˆì§€ ë„˜ì¹˜ê³  ê°œì„± ìˆëŠ” ëª©ì†Œë¦¬ë¡œ ì‹œì²­ìë“¤ê³¼ ì¹œê·¼í•˜ê²Œ ì†Œí†µí•˜ëŠ” ë° ìœ ë¦¬í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.",
        "ìƒë‹´ì‚¬": "ë¶€ë“œëŸ½ê³  ì•ˆì •ì ì¸ ìŒìƒ‰ì´ ìƒëŒ€ë°©ì—ê²Œ í¸ì•ˆí•¨ì„ ì£¼ì–´ ë§ˆìŒì„ ì—´ê²Œ ë§Œë“¤ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.",
        "ì„±ìš°": "ê¹¨ë—í•˜ê³  í‘œí˜„ë ¥ ì¢‹ì€ ëª©ì†Œë¦¬ë¡œ ìºë¦­í„°ì— ìƒë™ê°ì„ ë¶ˆì–´ë„£ì„ ìˆ˜ ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.",
        "ê°€ìˆ˜": "ë§‘ê³  ë§¤ë ¥ì ì¸ ìŒìƒ‰ê³¼ ë„“ì€ ìŒì—­ëŒ€ë¥¼ ê°€ì§€ê³  ìˆì–´ ë©œë¡œë””ë¥¼ í‘œí˜„í•˜ëŠ” ë° ê°•ì ì´ ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.",
        "êµì‚¬": "ì•ˆì •ì ì´ê³  ì‹ ë¢°ê° ìˆëŠ” ëª©ì†Œë¦¬ë¡œ í•™ìƒë“¤ì˜ ì§‘ì¤‘ë ¥ì„ ë†’ì´ê³  ì§€ì‹ì„ íš¨ê³¼ì ìœ¼ë¡œ ì „ë‹¬í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.",
        "íŒŸìºìŠ¤í„°": "ë‹¤ì±„ë¡œìš´ í†¤ê³¼ í¸ì•ˆí•œ ìŒìƒ‰ìœ¼ë¡œ ì¥ì‹œê°„ ì²­ì·¨ì—ë„ ì§€ë£¨í•˜ì§€ ì•Šì€ ë§¤ë ¥ì„ ì£¼ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.",
        "ê°•ì‚¬": "ì—ë„ˆì§€ ë„˜ì¹˜ê³  í˜ ìˆëŠ” ëª©ì†Œë¦¬ë¡œ ì²­ì¤‘ì„ ì••ë„í•˜ê³  ê°•ì˜ì— ëŒ€í•œ ì§‘ì¤‘ë„ë¥¼ ë†’ì´ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.",
        "í†µì—­ì‚¬": "ê¹¨ë—í•˜ê³  ì•ˆì •ì ì¸ í†¤ì´ ë³µì¡í•œ ë‚´ìš©ë„ ëª…í™•í•˜ê³  ì‹ ë¢°ê° ìˆê²Œ ì „ë‹¬í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.",
        "ë¼ë””ì˜¤ DJ": "ë¶€ë“œëŸ½ê³  í¸ì•ˆí•œ ëª©ì†Œë¦¬ê°€ ì²­ì·¨ìë“¤ê³¼ ê¹Šì€ ìœ ëŒ€ê°ì„ í˜•ì„±í•˜ëŠ” ë° ë§¤ìš° íš¨ê³¼ì ì´ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤."
    },
    "specialTags": ["ASMR ì²œì¬", "ëª©ì†Œë¦¬ ë§ˆì•½", "ê·€í˜¸ê°• ì£¼ì¸ê³µ", "ë³´ì´ìŠ¤ í”¼ì…”", "ìŒì„± ì¹˜ë£Œì‚¬", "íë§ ë³´ì´ìŠ¤", "ë§¤ë ¥ ë°œì‚°ê¸°", "ì¹´ë¦¬ìŠ¤ë§ˆ í­ë°œ", "ëª©ì†Œë¦¬ ê¿€", "ë³´ì»¬ DNA", "ìŒì„± ë§ˆìˆ ì‚¬", "ê·€ê° ì œì¡°ê¸°"],
    "voiceColors": ["ë£¨ë¹„ ë ˆë“œ", "ì‚¬íŒŒì´ì–´ ë¸”ë£¨", "ì—ë©”ë„ë“œ ê·¸ë¦°", "ê³¨ë“  ì˜ë¡œìš°", "ì•„ë©”ì‹œìŠ¤íŠ¸ í¼í”Œ", "ë‹¤ì´ì•„ëª¬ë“œ í™”ì´íŠ¸", "ì˜¤ë‹‰ìŠ¤ ë¸”ë™", "ë¡œì¦ˆ ê³¨ë“œ", "ì‹¤ë²„ í™”ì´íŠ¸", "ì½”ë°œíŠ¸ ë¸”ë£¨"]
}

# --- ìœ í‹¸ & ì „ì²˜ë¦¬ --- (ë³€ê²½ ì—†ìŒ)
def trim_and_normalize(y, sr):
    y = librosa.util.normalize(y)
    y, _ = librosa.effects.trim(y, top_db=30)
    return y

def median_filter_1d(x, k=5):
    if len(x) < k: return x
    pad = k // 2
    xp = np.pad(x, (pad, pad), mode='edge')
    return np.array([np.median(xp[i:i + k]) for i in range(len(x))])

# --- í”¼ì²˜ ì¶”ì¶œ í•¨ìˆ˜ë“¤ --- (ë³€ê²½ ì—†ìŒ)
def extract_pitch_stats(y, sr):
    f0, _, _ = librosa.pyin(y, fmin=librosa.note_to_hz('C2'), fmax=librosa.note_to_hz('C7'), frame_length=1024, hop_length=256, center=True)
    v = f0[~np.isnan(f0)]
    if len(v) == 0: return 150.0, 15.0, 80.0
    v = median_filter_1d(v, k=5)
    med = float(np.median(v))
    if len(v) == 1: return med, 15.0, 80.0
    std_hz = float(np.std(v))
    std_cents = float(1200.0 * np.std(np.log2(v / med)))
    return med, std_hz, std_cents

def analyze_energy(y):
    rms = librosa.feature.rms(y=y)[0]
    if np.all(rms == 0): return 0.0
    db = librosa.amplitude_to_db(rms, ref=np.max)
    norm = np.clip((db.mean() + 60.0) / 60.0, 0.0, 1.0)
    return float(norm)

def analyze_speaking_rate(y, sr):
    intervals = librosa.effects.split(y, top_db=30)
    yv = np.concatenate([y[s:e] for s, e in intervals]) if len(intervals) else y
    z = float(np.mean(librosa.feature.zero_crossing_rate(y=yv, frame_length=1024, hop_length=256)))
    S = np.abs(librosa.stft(yv, n_fft=1024, hop_length=256))
    flux = float(np.mean(np.maximum(0, np.diff(S, axis=1)).mean(axis=0)))
    proxy = 0.85 * z + 0.15 * (flux / np.maximum(S.mean(), 1e-6))
    return float(70 + (np.clip(proxy, 0.03, 0.18) - 0.03) / (0.18 - 0.03) * (180 - 70))

def analyze_harmonicity(y):
    y_h, y_p = librosa.effects.hpss(y)
    he = float(np.sum(y_h**2) + 1e-12)
    pe = float(np.sum(y_p**2) + 1e-12)
    hnr = 10.0 * np.log10(he / pe)
    return float(np.clip(hnr, -20.0, 20.0))

def analyze_spectral_centroid(y, sr):
    return float(np.mean(librosa.feature.spectral_centroid(y=y, sr=sr)))

# --- ë‚˜ì´ëŒ€ ì¶”ì • ê·œì¹™ --- (ë³€ê²½ ì—†ìŒ)
def get_age_key_female(pitch, spectral_centroid, energy_norm01):
    if pitch > 245: return "10s"
    elif pitch > 220: return "20s_early"
    elif pitch > 200: return "20s_late"
    elif pitch > 185: return "30s_early" if energy_norm01 > 0.5 else "30s_late"
    elif pitch > 170: return "40s_early" if spectral_centroid > 2200 else "40s_late"
    else: return "50s_plus"

def get_age_key_male(pitch, spectral_centroid, energy_norm01):
    if pitch > 165: return "10s"
    elif pitch > 140: return "20s_early"
    elif pitch > 125: return "20s_late"
    elif pitch > 110: return "30s_early" if energy_norm01 > 0.5 else "30s_late"
    elif pitch > 95: return "40s_early" if spectral_centroid > 1800 else "40s_late"
    else: return "50s_plus"

# --- í”„ë¡œí•„ ì‚°ì¶œ --- (ë³€ê²½ ì—†ìŒ)
def get_voice_profile(features):
    profile = set()
    if features['pitch'] > 180: profile.add('high_pitch')
    elif features['pitch'] < 130: profile.add('low_pitch')
    else: profile.add('mid_pitch')
    if features['energy'] > 0.75: profile.add('high_energy')
    elif features['energy'] < 0.30: profile.add('low_energy')
    else: profile.add('mid_energy')
    if features['harmonicity'] > 7.0: profile.add('clear_voice')
    elif features['harmonicity'] < 3.0: profile.add('husky_voice')
    else: profile.add('soft_voice')
    pitch_var = features.get('pitch_std_cents', None)
    if pitch_var is not None:
        profile.add('dynamic_tone' if pitch_var > 110.0 else 'stable_tone')
    else:
        profile.add('dynamic_tone' if features['pitch_std'] > 35 else 'stable_tone')
    return profile

# --- ì§ì—… ê°€ì¤‘ì¹˜ ìŠ¤ì½”ì–´ëŸ¬ ---
# CHANGED: ì¶”ì²œ ì´ìœ ë¥¼ í•¨ê»˜ ë°˜í™˜í•˜ë„ë¡ ìˆ˜ì •
def select_job_with_scores(profile, features, audio_bytes=None):
    jobs = ["ì•„ë‚˜ìš´ì„œ","MC","ì˜¤ë””ì˜¤ë¶ ë‚´ë ˆì´í„°","ë°°ìš°","ìœ íŠœë²„","ìƒë‹´ì‚¬", "ì„±ìš°","ê°€ìˆ˜","êµì‚¬","íŒŸìºìŠ¤í„°","ê°•ì‚¬","í†µì—­ì‚¬","ë¼ë””ì˜¤ DJ"]
    scores = {j: 0.0 for j in jobs}
    tempo = float(features.get("tempo", 110.0))
    fast, slow, mid_speed = tempo >= 120, tempo <= 95, 95 < tempo < 130
    def add(job, w): scores[job] += w
    # (ê°€ì¤‘ì¹˜ ë¡œì§ì€ ë³€ê²½ ì—†ìŒ)
    if 'clear_voice' in profile: add("ì•„ë‚˜ìš´ì„œ", 2.5)
    if 'stable_tone' in profile: add("ì•„ë‚˜ìš´ì„œ", 2.0)
    if 'mid_energy' in profile:  add("ì•„ë‚˜ìš´ì„œ", 1.0)
    if mid_speed:                add("ì•„ë‚˜ìš´ì„œ", 1.0)
    if 'high_energy' in profile and 'dynamic_tone' in profile: add("MC", 2.0)
    if fast:                                              add("MC", 2.0)
    if 'clear_voice' in profile:                          add("MC", 1.0)
    if 'low_energy' in profile: add("ì˜¤ë””ì˜¤ë¶ ë‚´ë ˆì´í„°", 2.0)
    if 'soft_voice' in profile: add("ì˜¤ë””ì˜¤ë¶ ë‚´ë ˆì´í„°", 2.0)
    if 'stable_tone' in profile: add("ì˜¤ë””ì˜¤ë¶ ë‚´ë ˆì´í„°", 1.0)
    if slow:                     add("ì˜¤ë””ì˜¤ë¶ ë‚´ë ˆì´í„°", 1.5)
    if 'dynamic_tone' in profile: add("ë°°ìš°", 2.0)
    if 'husky_voice' in profile:  add("ë°°ìš°", 1.0)
    if 'high_energy' in profile:  add("ë°°ìš°", 0.5)
    if 'high_energy' in profile: add("ìœ íŠœë²„", 1.5)
    if 'clear_voice' in profile: add("ìœ íŠœë²„", 1.0)
    if 'dynamic_tone' in profile: add("ìœ íŠœë²„", 1.0)
    if 'soft_voice' in profile:  add("ìƒë‹´ì‚¬", 2.0)
    if 'stable_tone' in profile: add("ìƒë‹´ì‚¬", 1.0)
    if 'low_energy' in profile:  add("ìƒë‹´ì‚¬", 1.0)
    if 'clear_voice' in profile: add("ì„±ìš°", 2.0)
    if 'dynamic_tone' in profile: add("ì„±ìš°", 1.0)
    if 'mid_energy' in profile:  add("ì„±ìš°", 1.0)
    if 'clear_voice' in profile: add("ê°€ìˆ˜", 1.0)
    if 'high_pitch' in profile:  add("ê°€ìˆ˜", 1.0)
    if 'dynamic_tone' in profile: add("ê°€ìˆ˜", 0.5)
    if 'stable_tone' in profile: add("êµì‚¬", 2.0)
    if 'mid_energy' in profile:  add("êµì‚¬", 1.0)
    if 'dynamic_tone' in profile: add("íŒŸìºìŠ¤í„°", 1.0)
    if 'soft_voice' in profile:   add("íŒŸìºìŠ¤í„°", 1.0)
    if 'mid_energy' in profile:   add("íŒŸìºìŠ¤í„°", 0.5)
    if 'high_energy' in profile: add("ê°•ì‚¬", 2.0)
    if fast:                     add("ê°•ì‚¬", 1.0)
    if 'clear_voice' in profile: add("ê°•ì‚¬", 0.5)
    if 'clear_voice' in profile: add("í†µì—­ì‚¬", 1.0)
    if 'stable_tone' in profile: add("í†µì—­ì‚¬", 1.0)
    if mid_speed:                add("í†µì—­ì‚¬", 1.0)
    if 'low_energy' in profile:  add("í†µì—­ì‚¬", 0.5)
    if 'soft_voice' in profile:  add("ë¼ë””ì˜¤ DJ", 1.0)
    if 'low_energy' in profile:  add("ë¼ë””ì˜¤ DJ", 0.5)
    if 'stable_tone' in profile: add("ë¼ë””ì˜¤ DJ", 0.5)

    ranked = sorted(scores.items(), key=lambda kv: kv[1], reverse=True)
    top3 = ranked[:3]
    if audio_bytes is not None and len(top3) > 1 and top3[0][1] == top3[1][1]:
        h = int(hashlib.md5(audio_bytes).hexdigest(), 16)
        top3 = sorted(top3, key=lambda kv: (kv[1], (h ^ hash(kv[0])) & 0xffff), reverse=True)

    best_job = top3[0][0]
    # CHANGED: ì§ì—… ì¶”ì²œ ì´ìœ  ê°€ì ¸ì˜¤ê¸°
    reason = voice_analysis_data["jobReasons"].get(best_job, "ë‹¹ì‹ ì˜ ë‹¤ì±„ë¡œìš´ ëª©ì†Œë¦¬ íŠ¹ì„±ê³¼ ì˜ ì–´ìš¸ë¦¬ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.")
    candidates = [{"job": j, "score": round(s, 2)} for j, s in top3]
    return best_job, reason, candidates


# --- ì„¸ë¶€ ê²°ê³¼ ë§¤í•‘ ---
# CHANGED: ë™ë¬¼ìƒ ì œê±°, ì„¤ëª… ì¶”ê°€ëœ ë°ì´í„° êµ¬ì¡° ì‚¬ìš©
def analyze_details_based_on_profile(profile, features=None, audio_bytes=None):
    voice_type_info = next(
        (vt for vt in voice_analysis_data["voiceTypes"] if all(p in profile for p in vt["profile_set"])),
        voice_analysis_data["voiceTypes"][-1] # Default (mint)
    )

    personality_type_map = {
        ('high_energy', 'dynamic_tone'): "ë¶„ìœ„ê¸° ë©”ì´ì»¤í˜•", ('low_energy', 'stable_tone'): "ê¹Šê³  ì°¨ë¶„í•œ ì•ˆì •í˜•",
        ('low_pitch', 'stable_tone'): "íƒ€ê³ ë‚œ ë¦¬ë”í˜•", ('high_pitch', 'dynamic_tone'): "ì°½ì˜ì ì¸ ì•„í‹°ìŠ¤íŠ¸í˜•",
        ('high_energy', 'clear_voice'): "í™œë™ì ì¸ ìŠ¤í¬ì¸ í˜•", ('husky_voice', 'dynamic_tone'): "ìœ ë¨¸ëŸ¬ìŠ¤í•œ ì¬ë¯¸í˜•",
        ('clear_voice', 'stable_tone'): "ì§€ì ì´ê³  ë¶„ì„ì ì¸ í˜•",
    }
    personality = "ë”°ëœ»í•œ ê°ì„±í˜•" # Default
    for p_set, p_type in personality_type_map.items():
        if all(p in profile for p in p_set):
            personality = p_type; break
    personality_type = next((item for item in voice_analysis_data["personalityTypes"] if item["type"] == personality), random.choice(voice_analysis_data["personalityTypes"]))

    job, reason, job_candidates = select_job_with_scores(profile, features, audio_bytes) if features else ("ë¼ë””ì˜¤ DJ", "ë¶€ë“œëŸ¬ìš´ ëª©ì†Œë¦¬ê°€ ë§¤ë ¥ì ì…ë‹ˆë‹¤.", [])

    tag_map = {
        ('low_energy', 'soft_voice'): "ASMR ì²œì¬", ('clear_voice', 'high_pitch'): "ê·€í˜¸ê°• ì£¼ì¸ê³µ",
        ('low_pitch', 'stable_tone'): "ì¹´ë¦¬ìŠ¤ë§ˆ í­ë°œ", ('soft_voice', 'clear_voice'): "ëª©ì†Œë¦¬ ê¿€",
        ('high_energy', 'dynamic_tone'): "ë§¤ë ¥ ë°œì‚°ê¸°", ('husky_voice', 'low_pitch'): "ë³´ì´ìŠ¤ í”¼ì…”",
    }
    tag = "íë§ ë³´ì´ìŠ¤" # Default
    for p_set, t_type in tag_map.items():
        if all(p in profile for p in p_set):
            tag = t_type; break

    color_map = {
        ('high_pitch', 'clear_voice'): "ì‚¬íŒŒì´ì–´ ë¸”ë£¨", ('high_pitch', 'high_energy'): "ê³¨ë“  ì˜ë¡œìš°",
        ('low_pitch', 'stable_tone'): "ì˜¤ë‹‰ìŠ¤ ë¸”ë™", ('low_pitch', 'husky_voice'): "ë£¨ë¹„ ë ˆë“œ",
        ('soft_voice', 'mid_pitch'): "ë¡œì¦ˆ ê³¨ë“œ", ('clear_voice', 'stable_tone'): "ì—ë©”ë„ë“œ ê·¸ë¦°",
        ('dynamic_tone', 'mid_energy'): "ì•„ë©”ì‹œìŠ¤íŠ¸ í¼í”Œ",
    }
    color = "ì‹¤ë²„ í™”ì´íŠ¸" # Default
    for p_set, c_type in color_map.items():
        if all(p in profile for p in p_set):
            color = c_type; break

    return {
        "voice_type": {k: v for k, v in voice_type_info.items() if k in ['type', 'desc']},
        "personality_type": {k: v for k, v in personality_type.items() if k not in ['id']},
        "compatibility_job": {"job": job, "reason": reason},
        "job_candidates": job_candidates,
        "special_tag": tag,
        "voice_color": color,
    }

# --- ë ˆì´ë” ì •ê·œí™” ---
def normalize_features_for_radar(features):
    pitch_score = np.nan_to_num((features["pitch"] - 80) / (250 - 80) * 100, nan=50.0)
    energy_score = np.nan_to_num(features["energy"] * 100, nan=50.0)
    tempo_score = np.nan_to_num((features["tempo"] - 70) / (180 - 70) * 100, nan=50.0)
    clearness_score = np.nan_to_num(features['harmonicity'] * 2.5 + 50, nan=50.0)
    
    # CHANGED: ì•ˆì •ê° ì ìˆ˜ ë¡œì§ ìˆ˜ì • (ë” ê´€ëŒ€í•˜ê²Œ)
    if "pitch_std_cents" in features:
        c = float(features["pitch_std_cents"])
        # 20(ë§¤ìš° ì•ˆì •)â†’95ì , 80(ë³´í†µ)â†’70ì , 150(ë‹¤ì´ë‚˜ë¯¹)â†’40ì ìœ¼ë¡œ ë§¤í•‘
        stability_score = np.interp(c, [20, 80, 150], [95, 70, 40])
    else:
        h = float(features["pitch_std"])
        stability_score = np.interp(h, [5, 20, 40], [95, 70, 40])

    stability_score = float(np.clip(stability_score, 10, 100))

    return [
        {"feature": "ë†’ì´", "value": int(np.clip(pitch_score, 10, 100))},
        {"feature": "ì—ë„ˆì§€", "value": int(np.clip(energy_score, 10, 100))},
        {"feature": "ì†ë„", "value": int(np.clip(tempo_score, 10, 100))},
        {"feature": "ë§‘ìŒ", "value": int(np.clip(clearness_score, 10, 100))},
        {"feature": "ì•ˆì •ê°", "value": int(np.clip(stability_score, 10, 100))},
    ]

def calculate_attraction_score(radar_data): # ë³€ê²½ ì—†ìŒ
    values = [item['value'] for item in radar_data]
    average_score = np.mean(values)
    std_dev = np.std(values)
    balance_bonus = max(0, 25 - std_dev)
    ideal_range_bonus = 10 if all(40 <= v <= 85 for v in values) else 0
    final_score = 60 + (average_score - 50) * 0.5 + balance_bonus + ideal_range_bonus
    return min(99, max(60, int(final_score)))

# --- í’ˆì§ˆ ì§„ë‹¨ --- (ë³€ê²½ ì—†ìŒ)
def estimate_snr(y):
    rms = librosa.feature.rms(y=y)[0]
    med = np.median(rms)
    noise = np.percentile(rms, 10)
    return float(20 * np.log10((med + 1e-8) / (noise + 1e-8)))

def clipping_ratio(y): return float(np.mean(np.abs(y) > 0.98))
def choose_deterministic(seq, audio_bytes):
    if not seq: return None
    h = int(hashlib.md5(audio_bytes).hexdigest(), 16)
    return seq[h % len(seq)]

# --- ì—”ë“œí¬ì¸íŠ¸ ---
@app.post("/api/analyze")
async def analyze_voice(gender: str = Form(...), audio: UploadFile = File(...)):
    try:
        # (íŒŒì¼ ì²˜ë¦¬ ë° í”¼ì²˜ ì¶”ì¶œì€ ë³€ê²½ ì—†ìŒ)
        if audio.content_type and not (audio.content_type.startswith("audio/") or audio.content_type == "application/octet-stream"):
            raise HTTPException(status_code=400, detail=f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì½˜í…ì¸  íƒ€ì…ì…ë‹ˆë‹¤: {audio.content_type}")
        audio_bytes = await audio.read()
        if not audio_bytes or len(audio_bytes) > MAX_BYTES:
             raise HTTPException(status_code=400, detail="íŒŒì¼ì´ ë¹„ì–´ìˆê±°ë‚˜ ë„ˆë¬´ í½ë‹ˆë‹¤.")
        try: sound = AudioSegment.from_file(io.BytesIO(audio_bytes))
        except Exception: raise HTTPException(status_code=400, detail="ì˜¤ë””ì˜¤ í¬ë§·ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        if sound.channels > 1: sound = sound.set_channels(1)
        samples = np.array(sound.get_array_of_samples()).astype(np.float32) / (2 ** (sound.sample_width * 8 - 1))
        target_sr = 22050
        y = librosa.resample(y=samples, orig_sr=sound.frame_rate, target_sr=target_sr)
        sr = target_sr
        y = trim_and_normalize(y, sr)
        if len(y) < int(MIN_SEC * sr): raise HTTPException(status_code=400, detail=f"ì˜¤ë””ì˜¤ ê¸¸ì´ê°€ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤(â‰¥{MIN_SEC:.1f}ì´ˆ í•„ìš”).")
        if len(y) > int(MAX_SEC * sr): y = y[:int(MAX_SEC * sr)]

        pitch_med, pitch_std_hz, pitch_std_cents = extract_pitch_stats(y, sr)
        energy, speaking_rate, hnr, spec_cent = analyze_energy(y), analyze_speaking_rate(y, sr), analyze_harmonicity(y), analyze_spectral_centroid(y, sr)

        features = {"pitch": pitch_med, "energy": energy, "tempo": speaking_rate, "pitch_std": pitch_std_hz, "pitch_std_cents": pitch_std_cents, "harmonicity": hnr}

        voice_profile = get_voice_profile(features)
        detailed_results = analyze_details_based_on_profile(voice_profile, features, audio_bytes)

        if gender == 'female': age_key = get_age_key_female(features["pitch"], spec_cent, features["energy"])
        else: age_key = get_age_key_male(features["pitch"], spec_cent, features["energy"])
        age_info = voice_analysis_data["age_groups"].get(age_key, voice_analysis_data["age_groups"]["30s_early"])

        radar_data = normalize_features_for_radar(features)
        attraction_score = calculate_attraction_score(radar_data)

        # CHANGED: ìœ ë‹ˆí¬ ì ìˆ˜ ë¡œì§ ë³€ê²½ (í‰ê· ì—ì„œ ë²—ì–´ë‚œ ì •ë„ë¡œ ê³„ì‚°)
        radar_values = np.array([item['value'] for item in radar_data])
        deviation_from_mean = np.mean(np.abs(radar_values - 50)) # 50ì„ í‰ê· ìœ¼ë¡œ ê°€ì •
        uniqueness_score = int(np.clip(50 + deviation_from_mean * 1.5, 50, 99))

        # (í’ˆì§ˆ ê²½ê³  ë° ê²°ê³¼ ì¡°í•© ë¶€ë¶„ì€ ë³€ê²½ ì—†ìŒ)
        snr, clip, voiced_ratio = estimate_snr(y), clipping_ratio(y), float(sum((e - s) for s, e in librosa.effects.split(y, top_db=30)) / len(y))
        warnings = []
        if snr < 10: warnings.append("ì£¼ë³€ ì†ŒìŒì´ ì»¤ì„œ ì •í™•ë„ê°€ ë–¨ì–´ì§ˆ ìˆ˜ ìˆì–´ìš”.")
        if clip > 0.02: warnings.append("ì…ë ¥ì´ í´ë¦¬í•‘ë˜ì—ˆìŠµë‹ˆë‹¤. ë§ˆì´í¬ ì…ë ¥ ë ˆë²¨ì„ ë‚®ì¶°ì£¼ì„¸ìš”.")
        if voiced_ratio < 0.4: warnings.append("ë¬´ìŒ êµ¬ê°„ì´ ë§ìŠµë‹ˆë‹¤. 2ì´ˆ ì´ìƒ ë˜ë°•ë˜ë°• ë§í•´ì£¼ì„¸ìš”.")

        humor = choose_deterministic(age_info["humor"], audio_bytes)

        result = {
            "version": API_VERSION,
            "age_range": age_info["range"],
            "humor_quote": humor,
            "attraction_score": attraction_score,
            "uniqueness_score": uniqueness_score,
            "radar_data": radar_data,
            "warnings": warnings,
            **detailed_results
        }
        return JSONResponse(content=result)

    except HTTPException: raise
    except Exception as e:
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"An error occurred during analysis: {str(e)}")

# (ë£¨íŠ¸ ë° í—¬ìŠ¤ ì²´í¬ ì—”ë“œí¬ì¸íŠ¸ëŠ” ë³€ê²½ ì—†ìŒ)
@app.get("/")
async def root(): return {"message": "Voice Age API is running!", "version": API_VERSION}
@app.get("/healthz")
async def healthz(): return {"status": "ok", "version": API_VERSION}